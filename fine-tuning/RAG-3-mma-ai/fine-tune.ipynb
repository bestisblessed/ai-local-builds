{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pickle\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build Your Knowledge Base\n",
    "\n",
    "# Load the fighter info and event data\n",
    "fighter_df = pd.read_csv(\"data-raw/fighter_info.csv\")\n",
    "event_df = pd.read_csv(\"data-raw/event_data_sherdog.csv\")\n",
    "\n",
    "# Merge fighter stats for Fighter 1\n",
    "merged = pd.merge(\n",
    "    event_df,\n",
    "    fighter_df,\n",
    "    left_on=[\"Fighter 1\", \"Fighter 1 ID\"],\n",
    "    right_on=[\"Fighter\", \"Fighter_ID\"],\n",
    "    suffixes=('', '_fighter1')\n",
    ")\n",
    "\n",
    "# Merge fighter stats for Fighter 2; note that fighter columns for Fighter 2 get suffixed with _fighter2\n",
    "merged = pd.merge(\n",
    "    merged,\n",
    "    fighter_df,\n",
    "    left_on=[\"Fighter 2\", \"Fighter 2 ID\"],\n",
    "    right_on=[\"Fighter\", \"Fighter_ID\"],\n",
    "    suffixes=('', '_fighter2')\n",
    ")\n",
    "\n",
    "# Create a document (text summary) for each fight event that includes both fighters' stats and the outcome.\n",
    "def create_document(row):\n",
    "    # For Fighter 1, use the columns without suffix; for Fighter 2, columns have a _fighter2 suffix.\n",
    "    doc = (\n",
    "        f\"Event on {row['Event Date']}: Fight between {row['Fighter 1']} and {row['Fighter 2']}.\\n\"\n",
    "        f\"{row['Fighter 1']} stats: Wins = {row['Wins']}, Losses = {row['Losses']}, \"\n",
    "        f\"Height = {row['Height']}, Birth Date = {row['Birth Date']}.\\n\"\n",
    "        f\"{row['Fighter 2']} stats: Wins = {row['Wins_fighter2']}, Losses = {row['Losses_fighter2']}, \"\n",
    "        f\"Height = {row['Height_fighter2']}, Birth Date = {row['Birth Date_fighter2']}.\\n\"\n",
    "        f\"Outcome: {row['Winning Fighter']} won by {row['Winning Method']} in round {row['Winning Round']} at {row['Winning Time']}.\"\n",
    "    )\n",
    "    return doc\n",
    "\n",
    "# Apply the function to create a new 'document' column\n",
    "merged['document'] = merged.apply(create_document, axis=1)\n",
    "\n",
    "# Create our knowledge base: a list of document texts (and a corresponding list of IDs)\n",
    "documents = merged['document'].tolist()\n",
    "document_ids = merged.index.tolist()\n",
    "\n",
    "print(f\"Created {len(documents)} documents for the knowledge base.\")\n",
    "print(\"\\nExample document:\")\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute Document Embeddings\n",
    "# Use a SentenceTransformer to convert each document into an embedding.\n",
    "\n",
    "# Load a pre-trained model (this model is fast and works well on a Mac)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for each document\n",
    "embeddings = model.encode(documents, convert_to_tensor=False, show_progress_bar=True)\n",
    "# embeddings = model.encode(documents, batch_size=2, convert_to_tensor=False, show_progress_bar=True)\n",
    "\n",
    "print(\"Generated embeddings for all documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build a FAISS Index\n",
    "# We use FAISS to index the embeddings so we can quickly retrieve the most relevant documents.\n",
    "\n",
    "# Convert the embeddings list to a numpy array of type float32\n",
    "embeddings_np = np.array(embeddings).astype('float32')\n",
    "d = embeddings_np.shape[1]  # dimensionality of the embeddings\n",
    "\n",
    "# Create a FAISS index (using L2 distance)\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings_np)\n",
    "\n",
    "print(f\"FAISS index built with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Example retrieval:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# sample_query = \"Predict the potential outcome for a fight between Jon Jones and Tom Aspinall.\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m sample_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredict the potential outcome for a fight between Belal Muhammad and Jack Delamadellena.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m retrieved_docs, distances \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved Documents:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc, dist \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(retrieved_docs, distances):\n",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36mretrieve_documents\u001b[0;34m(query, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_documents\u001b[39m(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute the query embedding\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mencode([query], convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     query_embedding_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(query_embedding)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Search the FAISS index for the top k closest embeddings\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 4: Create a Retrieval Function\n",
    "# This function takes a query, computes its embedding, and then retrieves the top‑k most similar documents from the FAISS index.\n",
    "\n",
    "def retrieve_documents(query, k=3):\n",
    "    # Compute the query embedding\n",
    "    query_embedding = model.encode([query], convert_to_tensor=False)\n",
    "    query_embedding_np = np.array(query_embedding).astype('float32')\n",
    "    \n",
    "    # Search the FAISS index for the top k closest embeddings\n",
    "    distances, indices = index.search(query_embedding_np, k)\n",
    "    \n",
    "    # Retrieve the corresponding documents\n",
    "    retrieved_docs = [documents[i] for i in indices[0]]\n",
    "    return retrieved_docs, distances[0]\n",
    "\n",
    "# Example retrieval:\n",
    "# sample_query = \"Predict the potential outcome for a fight between Jon Jones and Tom Aspinall.\"\n",
    "sample_query = \"Predict the potential outcome for a fight between Belal Muhammad and Jack Delamadellena.\"\n",
    "retrieved_docs, distances = retrieve_documents(sample_query, k=3)\n",
    "\n",
    "print(\"Retrieved Documents:\")\n",
    "for doc, dist in zip(retrieved_docs, distances):\n",
    "    print(f\"Distance: {dist:.2f} - {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieved_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Example generation:\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m prediction \u001b[38;5;241m=\u001b[39m generate_prediction(sample_query, \u001b[43mretrieved_docs\u001b[49m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieved_docs' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 5: Integrate with an LLM for Generation\n",
    "# Finally, create a prompt that includes your query and the retrieved documents. Then call OpenAI’s API to generate a prediction.\n",
    "\n",
    "# sample_query = \"Predict the potential outcome for a fight between Jon Jones and Tom Aspinall.\"\n",
    "sample_query = \"Predict the potential outcome for a fight between Belal Muhammad and Jack Delamadellena.\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # Or directly: api_key=\"your-key-here\"\n",
    ")\n",
    "\n",
    "def generate_prediction(query, retrieved_docs):\n",
    "    # Combine the retrieved documents into a single context string\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    \n",
    "    # Construct the prompt: it includes the context and the query\n",
    "    prompt = (\n",
    "        f\"Analyze the following historical fight data:\\n{context}\\n\\n\"\n",
    "        f\"Given the matchup query: '{query}', predict the winner, method of victory, and the round in which the fight might end. \"\n",
    "        \"Provide a concise answer in one sentence.\"\n",
    "    )\n",
    "    \n",
    "    # Call the OpenAI ChatCompletion API\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable MMA fight analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    # Change from ['content'] to .content\n",
    "    print(response)\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    return answer\n",
    "\n",
    "# Example generation:\n",
    "prediction = generate_prediction(sample_query, retrieved_docs)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "# 1. Save model\n",
    "model.save(\"mma_prediction_model\")  # Creates a folder with model files\n",
    "print(\"Saved model to 'mma_prediction_model' folder\")\n",
    "\n",
    "# 2. Save FAISS index\n",
    "faiss.write_index(index, \"mma_faiss_index.index\")\n",
    "print(\"Saved FAISS index to 'mma_faiss_index.index'\")\n",
    "\n",
    "# 3. Save documents\n",
    "with open(\"mma_documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents, f)\n",
    "print(\"Saved documents to 'mma_documents.pkl'\")\n",
    "\n",
    "# 4. Save document IDs (if needed)\n",
    "with open(\"mma_document_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(document_ids, f)\n",
    "print(\"Saved document IDs to 'mma_document_ids.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reload Model and ask Question (if you dont wanna rebuild) ###\n",
    " \n",
    "model = SentenceTransformer('mma_prediction_model')\n",
    "index = faiss.read_index(\"mma_faiss_index.index\")\n",
    "\n",
    "with open(\"mma_documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "    \n",
    "with open(\"mma_document_ids.pkl\", \"rb\") as f:\n",
    "    document_ids = pickle.load(f)\n",
    "    \n",
    "    \n",
    "# Define the retrieval function AFTER loading resources\n",
    "def retrieve_documents(query, k=3):\n",
    "    query_embedding = model.encode([query], convert_to_tensor=False)\n",
    "    query_embedding_np = np.array(query_embedding).astype('float32')\n",
    "    distances, indices = index.search(query_embedding_np, k)\n",
    "    return [documents[i] for i in indices[0]], distances[0]\n",
    "\n",
    "\n",
    "# After loading saved resources but before generation\n",
    "sample_query = \"Predict the potential outcome for a fight between Belal Muhammad and Jack Delamadellena.\"\n",
    "\n",
    "# First retrieve documents\n",
    "retrieved_docs, distances = retrieve_documents(sample_query, k=3)  # Add this line\n",
    "\n",
    "# Then generate prediction\n",
    "prediction = generate_prediction(sample_query, retrieved_docs)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
